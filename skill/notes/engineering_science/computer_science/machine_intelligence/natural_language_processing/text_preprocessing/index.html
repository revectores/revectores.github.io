<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title> Natural Language Processing
 </title>
  <link rel="stylesheet" type="text/css" href="http://revectores.com/static/css/newsprint.css"> 
  <link rel="stylesheet" type="text/css" href="http://revectores.com/static/css/blog.css"> 
  <link rel="stylesheet" type="text/css" href="http://revectores.com/static/css/code.css"> 
</head>
<body>

<p><a href="../"><< natural_language_processing</a></p>

<h1 id="natural-language-processing">Natural Language Processing</h1>
<h3 id="introduction">1. Introduction</h3>
<h5 id="basic-procedures"># Basic Procedures</h5>
<p>The following basic steps are included in natural language processing:</p>
<pre class="mermaid"><code>graph TB;

ss[Sentence Segmentation]
wt[Word Tokenization]
ss --&gt; wt</code></pre>
<h1 id="text-preprocessing">Text Preprocessing</h1>
<h3 id="filtering">1. Filtering</h3>
<h3 id="text-tokenization">2. Text Tokenization</h3>
<p>The process converting the sequences into <strong>token</strong> is <strong>tokenization</strong>, the lexical analyzer classify the token during this process.</p>
<p>Let <span class="math inline">\(N\)</span> denotes the number of tokens, and <span class="math inline">\(V\)</span> denotes vocabulary(set of types), <span class="math inline">\(|V|\)</span> is the size of vocabulary. The relation <span class="math inline">\(|V|&gt; O(\sqrt N)\)</span> has been proved by ==TODO==.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="im">import</span> nltk.tokenize <span class="im">as</span> tk</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>doc <span class="op">=</span> <span class="st">&quot;Are you curious about tokenization? Let&#39;s see how it works! We need to analyze a couple of sentences, with punctuations to see it in action.&quot;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>sent_tokens <span class="op">=</span> tk.sent_tokenize(doc)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>word_tokens <span class="op">=</span> tk.word_tokenize(doc)</span></code></pre></div>
<p>The <code>tk.sent_tokenize</code> method split the document as sentences, and <code>tk.word_tokenize</code> as words. Specially, the class with its method <code>WordPunctTokenizer.tokenize</code> is provided to regard the punct as a word.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>tokenizer <span class="op">=</span> tk.WordPunctTokenizer()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>tokens <span class="op">=</span> tokenizer.tokenize(doc)</span></code></pre></div>
<h3 id="stemming-and-lemmatisation">3. Stemming and Lemmatisation</h3>
<p><strong>Stemming</strong> removes the syntax prefix/suffix to get the stem of a word, and <strong>lemmatisation</strong> converts the wordâ€™s complex form ito its original form. Sometimes ==TODO== is required</p>
<pre class="mermaid"><code>stateDiagram-v2

state stemming{
    plays --&gt; play
    played --&gt; play
    playing --&gt; play
}

state lemmatisation {
    is --&gt; be
    are --&gt; be
    been --&gt; be
}</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="im">import</span> nltk</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="im">import</span> nltk.stem.porter <span class="im">as</span> pt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a><span class="im">import</span> nltk.stem.lancaster <span class="im">as</span> lc</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a><span class="im">import</span> nltk.stem.snowball <span class="im">as</span> sb</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a><span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>    stem_pt <span class="op">=</span> pt.PorterStemmer().stem(word)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>    stem_lc <span class="op">=</span> lc.LancasterStemmer().stem(word)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>    stem_sb <span class="op">=</span> sb.Snowball().stem(word)</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="im">import</span> nltk.stem <span class="im">as</span> ns</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>lemmatizer <span class="op">=</span> ns.WordNetLemmatizer()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a><span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>    n_lemma <span class="op">=</span> lemmatizer.lemmatize(word, pos<span class="op">=</span><span class="st">&#39;n&#39;</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a>    v_lemma <span class="op">=</span> lemmatizer.lemmatize(word, pos<span class="op">=</span><span class="st">&#39;v&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="im">import</span> re</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a><span class="cf">with</span> <span class="bu">open</span>() <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a>    content <span class="op">=</span> <span class="bu">file</span>.read()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a>    </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true"></a>pattern <span class="op">=</span> re.<span class="bu">compile</span>()</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true"></a>content <span class="op">=</span> </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true"></a>tokens <span class="op">=</span> tk.word_tokenize</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true"></a>tokens <span class="op">=</span> []</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true"></a>tokens_pos <span class="op">=</span> </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true"></a>result.append(PorterStemmer().stem(token))</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true"></a>result.append(lemmatizer.lemmatize(token, pos<span class="op">=</span>postag))</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true"></a>Counter(result).most_common(<span class="dv">100</span>)</span></code></pre></div>


</body>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</html>
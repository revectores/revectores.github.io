<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title> Probability Basic
 </title>
  <link rel="stylesheet" type="text/css" href="http://revectores.com/static/css/newsprint.css"> 
  <link rel="stylesheet" type="text/css" href="http://revectores.com/static/css/blog.css"> 
  <link rel="stylesheet" type="text/css" href="http://revectores.com/static/css/code.css"> 
</head>
<body>

<p><a href="../"><< probability_and_statistics</a></p>

<h1 id="probability-basic">Probability Basic</h1>
<p><span class="math display">\[
\newcommand{\F}{\mathcal{F}}
\newcommand{\o}{\overline}
\]</span></p>
<h3 id="axiomatization">2. Axiomatization</h3>
<h5 id="event-domain"># Event Domain</h5>
<p>Let <span class="math inline">\(\Omega\)</span> be the <strong>sample space</strong>, if <span class="math inline">\(\F\subset\Omega\)</span> meets</p>
<ol type="1">
<li><span class="math inline">\(\Omega\in\F\)</span>.</li>
<li>For any <span class="math inline">\(A\in\F\)</span>, <span class="math inline">\(\overline A\in\F\)</span>.</li>
<li>For <span class="math inline">\(A_i\in\F, i\lt n\)</span>, <span class="math inline">\(\displaystyle\bigcup_{n=1}^{\infty}A_n\in\F\)</span>.</li>
</ol>
<p>Then we defined <span class="math inline">\(\F\)</span> as <strong>event domain</strong> in the sample space <span class="math inline">\(\Omega\)</span>.</p>
<h5 id="probability-space"># Probability Space</h5>
<p>Let <span class="math inline">\(P\)</span> be the real function in event domain <span class="math inline">\(\F\)</span>, it is defined as <strong>probability measure</strong> or <strong>probability</strong> if holds</p>
<ol type="1">
<li>Non-negative. <span class="math inline">\(P(A)\ge0\)</span>.</li>
<li>Regularity. <span class="math inline">\(P(\Omega) = 1\)</span>. ==TODO: this translation needs further evidences to support==</li>
<li>Countable Additivity. For the incompatible event list <span class="math inline">\(A_{i}\)</span>, <span class="math inline">\(P\left(\displaystyle\sum_{i=1}^{\infty}{A_i}\right) = \displaystyle\sum_{i=1}^{\infty}P(A_i)\)</span>.</li>
</ol>
<p>The triple <span class="math inline">\((\Omega, \F, P)\)</span> called <strong>probability space</strong>, where <span class="math inline">\(\Omega\)</span> is sample space, <span class="math inline">\(\F\)</span> is the event domain, and <span class="math inline">\(P\)</span> is the probability measure.</p>
<p>Notice that in the definition, the countable additivity is the infinity form, while we’ll proved the finite form based on it in the next section as the property of probability.</p>
<h5 id="basic-property"># Basic Property</h5>
<p>Several Properties can be inferred from the axiomationzation of probability:</p>
<ol type="1">
<li>The probability of impossible event is 0. i.e. <span class="math inline">\(P(\varnothing)=0\)</span></li>
</ol>
<blockquote>
<p>Proof. Let <span class="math inline">\(A_{1} = \Omega\)</span>, <span class="math inline">\(A_{i} = \varnothing\)</span> for <span class="math inline">\(i\ge2\)</span>, notice that <span class="math inline">\(\Omega \cap \varnothing = \varnothing \cap \varnothing = \varnothing\)</span>, hence, this is an incompatible event list, based on the conutable addivity,</p>
<p><span class="math display">\[
P\left(\Omega + \sum_{i=2}^{\infty} \varnothing\right)
= P(\Omega) + P(\varnothing)\sum_{i=2}^{\infty} 1
= 1 + P(\varnothing)\sum_{i=2}^{\infty} 1\le 1
\]</span></p>
<p>Hence <span class="math inline">\(P(\varnothing) = 0\)</span>.</p>
</blockquote>
<ol start="2" type="1">
<li>The countable additivity can be reduced to the finite form.</li>
</ol>
<blockquote>
<p>Proof. For finite event <span class="math inline">\(A_i, i\le n\)</span>, we expand the subscript <span class="math inline">\(A_i = \varnothing\)</span> for <span class="math inline">\(i\gt n\)</span>, notice that <span class="math inline">\(A_i\cap \varnothing = \varnothing\)</span> for any event <span class="math inline">\(A_{i}\)</span>, which guranteed <span class="math inline">\(A_i\)</span> is an incompatible event list, thus</p>
<p><span class="math display">\[
P\left(\sum_{i=1}^{n} A_i \right)
= P\left(\sum_{i=1}^{n} A_i + \sum_{i=n+1}^{\infty} \varnothing\right)
= P\left(\sum_{i=1}^{n} A_i \right) + P \left( \sum_{i=n+1}^{\infty} \varnothing \right)
= P\left(\sum_{i=1}^{n} A_i \right)
\]</span></p>
</blockquote>
<ol start="3" type="1">
<li><p><span class="math inline">\(P(\overline A) + P(A) = 1\)</span></p></li>
<li><p>For <span class="math inline">\(B\subset A\)</span>, <span class="math inline">\(P(A-B) = P(A) - P(B)\)</span>. Generally, <span class="math inline">\(P(A\backslash B) = P(A) - P(AB)\)</span>.</p>
<p><strong>Corollary</strong>. For <span class="math inline">\(B\subset A\)</span>, <span class="math inline">\(P(B)\le P(A)\)</span></p></li>
<li><p><span class="math inline">\(0\le P(A)\le1\)</span>.</p></li>
<li><p><span class="math inline">\(P(A\cup B) = P(A) + P(B) - P(AB)\)</span>.</p>
<p><strong>Corollary</strong>. <span class="math inline">\(P(A\cup B) \le P(A) + P(B)\)</span>.</p></li>
</ol>
<h3 id="possiblity-model">3. Possiblity Model</h3>
<p>The <strong>classical probability</strong> and <strong>geometric probability</strong> are two model of probability that represents the discrete and continous case respectively.</p>
<p>More precisely, in the study of classical probability, there are some typical patterns that arised in many different problems, i.e. the (put back or not) sampling model, box model, pair model.</p>
<p>==TODO: Add illustrations to common possibility models into this section.==</p>
<h3 id="conditional-probability">4. Conditional Probability</h3>
<h5 id="definition"># Definition</h5>
<p>Given probability space <span class="math inline">\((\Omega, \F, P)\)</span>, and <span class="math inline">\(B\in\F, P(B)&gt;0\)</span>, for any <span class="math inline">\(A\in\F\)</span>, we define</p>
<p><span class="math display">\[
P(A|B) := \frac{P(AB)}{P(B)}
\]</span></p>
<p>as the <strong>conditional probability</strong> of <span class="math inline">\(A\)</span> if <span class="math inline">\(B\)</span> is known occured.</p>
<p>One basic but important fact is, the conditional probability is a type of probability, aka. it complies with the axiomatization of probability:</p>
<ol type="1">
<li><p>Non-negative. Since <span class="math inline">\(P(AB), P(B)\ge0\)</span>, the conditional probability <span class="math inline">\(P(A|B) = \cfrac{P(AB)}{P(B)}\ge0\)</span></p></li>
<li><p>Normal. <span class="math inline">\(P(\Omega|B) = \cfrac{P(\Omega B)}{P(B)} = \cfrac{P(B)}{P(B)} = 1\)</span>.</p></li>
<li><p>Countable addivitity. For the incompatible event list <span class="math inline">\(A_{i}\)</span>, <span class="math inline">\(A_{i}B\)</span> is also an incompatible event list.</p></li>
</ol>
<p><span class="math display">\[
P\left(\left.\sum_{i=1}^{\infty}{A_i} \right\vert B\right)
= \cfrac{P\left(\displaystyle\sum_{i=1}^{\infty} A_iB\right)}{P(B)}
= \cfrac{\displaystyle\sum_{i=1}^{\infty} P\left(A_iB\right)}{P(B)}
= \sum_{i=1}^{\infty} \cfrac{P\left(A_iB\right)}{P(B)}
= \sum_{i=1}^{\infty}P(A_i|B)
\]</span></p>
<p>By illustrating the three properties above, we proved that the conditional probability is definitely probability.</p>
<h5 id="property"># Property</h5>
<p>As proved above, the conditional probability is probability, which means it shares all the properties of the general probability, besides, there are some special properties that only for conditional probability, here list some trivial examples:</p>
<ul>
<li><span class="math inline">\(P(B|B) = 1\)</span>.</li>
<li>If <span class="math inline">\(P(B) = 1\)</span>, <span class="math inline">\(P(A|B) = P(A)\)</span>.</li>
<li>If <span class="math inline">\(AB = \varnothing\)</span>.</li>
<li>If <span class="math inline">\(A\subset B\)</span>, <span class="math inline">\(P(A|B) = \cfrac{P(A)}{P(B)}\)</span></li>
</ul>
<p>And there important features:</p>
<ol type="1">
<li><p><strong>Formula of Multiplication</strong></p>
<p>For the given probability space <span class="math inline">\((\Omega, \F, P), A_1, A_2, ..., A_n\in\F\)</span>, and <span class="math inline">\(P(A_{1}A_{2}...A_{n}) &gt; 0\)</span>, we have <span class="math display">\[
 P(A_{1}A_{2}...A_{n}) = P(A_{1})P(A_{2}|A_{1})...P(A_{n}|A_{1}A_{2}...A_{n-1})
 \]</span> and for the case of two events: <span class="math display">\[
 P(AB) = P(A)P(B|A) = P(B)P(A|B)
 \]</span></p></li>
</ol>
<blockquote>
<p><strong>Proof</strong>. Induction on <span class="math inline">\(n\)</span>:</p>
<p><strong>Basis</strong>. <span class="math inline">\(n=2\)</span> case is guranteed by the definition of conditional probability: <span class="math display">\[
P(A_1|A_2) = \cfrac{P(A_1A_2)}{P(A_2)} ~~~~\Rightarrow ~~~~ P(A_1A_2) = P(A_1)P(A_1|A_2)
\]</span></p>
<p><strong>Induction</strong>. Assume the <span class="math inline">\(n=k\)</span> case is correct, for <span class="math inline">\(n=k+1\)</span>. <span class="math display">\[
P(A_{1}A_{2}...A_{k}) = P(A_{1}A_{2}...A_{k-1})P(A_{k}|A_{1}A_{2}...A_{k-1})
\]</span></p>
<p>Notice that <span class="math inline">\(P(A_1A_2...A_n) &gt; 0\)</span> gives <span class="math inline">\(P(A_1) \ge P(A_1A_2) \ge \cdots \ge P(A_1A_2...A_n) &gt; 0\)</span>, which gurantees the validity of all the expression of conditional probability. That concludes the formula of multiplication for any <span class="math inline">\(n\ge2\)</span> is correct.</p>
</blockquote>
<ol start="2" type="1">
<li><p><strong>Total Probability Formula</strong></p>
<p>Let <span class="math inline">\(E_{1}, E_{2}, ..., E_{n}\)</span> be a partition of sample space <span class="math inline">\(\Omega\)</span>, and for each part <span class="math inline">\(P(E_{i})\gt 0\)</span>, for any event <span class="math inline">\(A\in\F\)</span>, <span class="math display">\[
 P(A) = \sum_{k=1}^{n}P(E_k)P(A|E_k)
 \]</span> and for the case of two events: <span class="math display">\[
 P(A) = P(A|B)P(B) + P(A|\o B)P(\o B)
 \]</span></p></li>
</ol>
<blockquote>
<p><strong>Proof</strong>. This can be proved simply by the additivity and formula of multiplication: <span class="math display">\[
P(A)
= P(A\Omega)
= P\left(A\sum_{k=1}^n{E_k}\right)
= \sum_{k=1}^n P\left( AE_k \right)
= \sum_{k=1}^n P(E_k)P(A|E_k)
\]</span></p>
</blockquote>
<ol start="3" type="1">
<li><p><strong>Bayes Formula</strong></p>
<p>Let <span class="math inline">\(E_{1}, E_{2}, ..., E_{n}\)</span> be a partition of sample space <span class="math inline">\(\Omega\)</span>, and for each part <span class="math inline">\(P(E_{i})\gt 0\)</span>, then for any event <span class="math inline">\(A\)</span> and the part <span class="math inline">\(E_i\)</span>,</p>
<p><span class="math display">\[
 P(E_i|A) = \cfrac{P(AE_{i})}{P(A)} = \cfrac{P(E_i)P(A|E_i)}{\displaystyle\sum_{k=1}^{n}P(E_k)P(A|E_k)}
 \]</span> The Bayes formula is the synthesization of definition of conditional probability, formula of multiplication and total probability formula. Physically, we use the prior knowledge, which is the prior probability <span class="math inline">\(P(E_k)\)</span> of reasons as the basis, trying find out the probability of reason <span class="math inline">\(P(E_i|A)\)</span> by introducing the new knowledge <span class="math inline">\(P(A|E_k)\)</span>.</p>
<p>Actually, Bayes formula is quite a quantification of the common sense in belief updating, hence it has been applied in a wide range of domains nowadays. See <a href="naïve_bayes_algorithm.md">naïve_bayes_algorithm</a>.</p>
<p>==MODEL_CONNECTION: Due to the significant rule of Bayes formula in the movement conducting system, we’ve introduce the parse <strong>Bayes’ Ghost</strong> to represent the event <span class="math inline">\(A\)</span> in <span class="math inline">\(P(E_i|A)\)</span>, who helps us update the prediction of probability of success <span class="math inline">\(P(E_i)\)</span>. We use the parse “introduce/expel Bayes’ Ghost” to represent “execute/avoid <span class="math inline">\(A\)</span>”==.</p>
<p>Finally, since the conditional probability is probability, the conditional version of three properties above can be included formally.</p></li>
</ol>
<h3 id="independency">5. Independency</h3>
<h5 id="definition-1"># Definition</h5>
<p>Two events <span class="math inline">\(A, B\)</span> are <strong>independent</strong> if <span class="math display">\[
P(AB) = P(A)P(B)
\]</span> The “independency” or “not relavent” of the two events can be comprehended more easily from the conditional probability form: <span class="math display">\[
P(AB) = P(A)P(B) \Rightarrow
\left\{
\begin{array}{ll}
\begin{align}
&amp;P(A) = \frac{P(AB)}{P(B)} = P(A|B) \\
&amp;P(B) = \frac{P(AB)}{P(A)} = P(B|A) \\
\end{align}
\end{array}
\right.
\]</span> That is, the conditional probability is the same as the unconditional one, this can be regarded as another form of the definition of independency.</p>
<p>Specially, the zero-probability event (including impossible event <span class="math inline">\(\varnothing\)</span>) is independent to any event. This can be derived from the monotonicity of probability.</p>
<h5 id="independency-in-multiple-events"># Independency in Multiple Events</h5>
<p>For multiple events <span class="math inline">\(A_i (1\le i\le n)\)</span>, <span class="math inline">\(A_i\)</span> are <strong>pairwise(2-wise) independent</strong>, if for any <span class="math inline">\(1\le i,j \le n\)</span>, <span class="math display">\[
P(A_iA_j) = P(A_i)P(A_j)
\]</span> Generally, the <strong>k-wise independence</strong> (where <span class="math inline">\(k&lt;n\)</span>) are defined as for any <span class="math inline">\(k\)</span> events <span class="math inline">\(1\le i_1, i_2, ... i_k \le n\)</span>, <span class="math display">\[
P\left( \bigcap_{j=1}^{k} A_{i_j} \right) = \prod_{j=1}^{k}A_{i_j}
\]</span> One should notice that the there are no determined relations between different k-wise independency, i.e. you cannot derive 2-wise dependency from 3-wise dependency, or vice versa.</p>
<p>Multiple events <span class="math inline">\(A_i, 1\le i\le n\)</span> are defined as <strong>independent</strong>, if and only if the <span class="math inline">\(n\)</span> events are k-wise independent for all <span class="math inline">\(2\le k\le n\)</span>.</p>
<p>Consider about the special case about 3-events <span class="math inline">\(A, B, C\)</span> are independent, that indicates the following restrictions: <span class="math display">\[
\begin{align}
&amp; P(AB) = P(A)P(B) \\
&amp; P(AC) = P(A)P(C) \\
&amp; P(BC) = P(B)P(C) \\
&amp; P(ABC)=P(A)P(B)P(C)
\end{align}
\]</span> Generally, for the n-events independent, $_{i=2}^n {ni} = 2^n - n -1 $ restrictions will be introduced.</p>
<h5 id="property-1"># Property</h5>
<ol type="1">
<li><p>If event <span class="math inline">\(A\)</span> is independent with itself, then either <span class="math inline">\(P(A)=0\)</span> or <span class="math inline">\(P(A)=1\)</span>.</p>
<blockquote>
<p>Proof. Based on the definition of independency, we have <span class="math display">\[
P(A) = [P(A)]^2
\]</span> Hence <span class="math inline">\(P(A) = 0\)</span> or <span class="math inline">\(P(A) = 1\)</span>.</p>
</blockquote></li>
<li><p>If the event list <span class="math inline">\(A_i, 1\le i\le n\)</span> are independent, then <span class="math inline">\(A_1,~...~, \overline{A_i}, ~...~ , A_n\)</span> are also independent. That is, you can reverse any event of an independent events list but keep the independency still. Specially, the reversed list <span class="math inline">\(\overline{A_i}, 1\le i \le n\)</span> are independent still.</p>
<blockquote>
<p>This property can be comprehended by the meaning of “independency”, if one event is “indenpendent”, then the occurance, or the not orccurance, are both not relavent with the others, hence we can replace it with its opposite event.</p>
<p>We’ll prove this for the 2-event cases: If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, then <span class="math inline">\(A\)</span> and <span class="math inline">\(\overline B\)</span> are also independent.</p>
<p><strong>Proof</strong>. <span class="math display">\[
\begin{align}
P(A\o B)
&amp;= P(A - AB) \\
&amp;= P(A) - P(AB) \\
&amp;= P(A) - P(A)P(B) \\
&amp;= P(A)(1-P(B)) \\
&amp;= P(A)P(\o B)
\end{align}
\]</span></p>
</blockquote></li>
<li><p>For the independent events <span class="math inline">\(A_1, ..., A_n (n\ge 2)\)</span>, the Poincaré formula, the addition formula of events, can be simplified as <span class="math display">\[
 P\left( \bigcup_{k=1}^n A_k \right) = 1 - \prod_{k=1}^n(1-P(A_k))
 \]</span></p>
<blockquote>
<p><strong>Proof</strong>. <span class="math display">\[
\begin{align}
P\left( \bigcup_{k=1}^n A_k \right)
&amp;= 1 - P\left( \o{\bigcup_{k=1}^n A_k} \right) \\
&amp;= 1 - P\left( \bigcap_{k=1}^n \o{A_k} \right) \\
&amp;= 1 - \prod_{k=1}^n P(\o{A_k}) \\
&amp;= 1 - \prod_{k=1}^n(1-P(A_k)) \\
\end{align}
\]</span></p>
</blockquote>
<p>This implies that, for any events <span class="math inline">\(A_1, A_2, ..., A_n\)</span> with same <span class="math inline">\(P(A_i) = \delta\)</span>, no matter how small the probability one event is, the probability of at least one success will finally approaches <span class="math inline">\(1\)</span> with enough experiments.</p></li>
</ol>


</body>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</html>